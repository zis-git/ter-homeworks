# Домашнее задание к занятию «Основы Terraform. Yandex Cloud»  Голоха Е.В.

### Цели задания

1. Создать свои ресурсы в облаке Yandex Cloud с помощью Terraform.
2. Освоить работу с переменными Terraform.


### Чек-лист готовности к домашнему заданию

1. Зарегистрирован аккаунт в Yandex Cloud. Использован промокод на грант.
2. Установлен инструмент Yandex CLI.
3. Исходный код для выполнения задания расположен в директории [**02/src**](https://github.com/netology-code/ter-homeworks/tree/main/02/src).


### Задание 0

1. Ознакомьтесь с [документацией к security-groups в Yandex Cloud](https://cloud.yandex.ru/docs/vpc/concepts/security-groups?from=int-console-help-center-or-nav). 
Этот функционал понадобится к следующей лекции.

------
### Внимание!! Обязательно предоставляем на проверку получившийся код в виде ссылки на ваш github-репозиторий!
------

### Задание 1
В качестве ответа всегда полностью прикладывайте ваш terraform-код в git.
Убедитесь что ваша версия **Terraform** ~>1.12.0

1. Изучите проект. В файле variables.tf объявлены переменные для Yandex provider.
2. Создайте сервисный аккаунт и ключ. [service_account_key_file](https://terraform-provider.yandexcloud.net).
4. Сгенерируйте новый или используйте свой текущий ssh-ключ. Запишите его открытую(public) часть в переменную **vms_ssh_public_root_key**.
5. Инициализируйте проект, выполните код. Исправьте намеренно допущенные синтаксические ошибки. Ищите внимательно, посимвольно. Ответьте, в чём заключается их суть.
6. Подключитесь к консоли ВМ через ssh и выполните команду ``` curl ifconfig.me```.
Примечание: К OS ubuntu "out of a box, те из коробки" необходимо подключаться под пользователем ubuntu: ```"ssh ubuntu@vm_ip_address"```. Предварительно убедитесь, что ваш ключ добавлен в ssh-агент: ```eval $(ssh-agent) && ssh-add``` Вы познакомитесь с тем как при создании ВМ создать своего пользователя в блоке metadata в следующей лекции.;
8. Ответьте, как в процессе обучения могут пригодиться параметры ```preemptible = true``` и ```core_fraction=5``` в параметрах ВМ.

В качестве решения приложите:

- скриншот ЛК Yandex Cloud с созданной ВМ, где видно внешний ip-адрес;
- скриншот консоли, curl должен отобразить тот же внешний ip-адрес;
- ответы на вопросы.


### Решение 1

Для подключения к Yandex Cloud я не хардкодил cloud_id, folder_id, зону и токен в провайдере.
Все значения вынесены в переменные (var.cloud_id, var.folder_id, var.default_zone).
Авторизация производится через service_account_key_file, путь к файлу ключа, а не через прямой OAuth-токен в коде.

variables.tf (фрагмент):

""
variable "cloud_id" {
  type        = string
  description = "https://cloud.yandex.ru/docs/resource-manager/operations/cloud/get-id"
}

variable "folder_id" {
  type        = string
  description = "https://cloud.yandex.ru/docs/resource-manager/operations/folder/get-id"
}

variable "default_zone" {
  type        = string
  default     = "ru-central1-a"
  description = "https://cloud.yandex.ru/docs/overview/concepts/geo-scope"
}

variable "default_cidr" {
  type        = list(string)
  default     = ["10.0.1.0/24"]
  description = "CIDR для подсети"
}

variable "vpc_name" {
  type        = string
  default     = "develop"
  description = "VPC network & subnet name"
}
""

terraform.tfvars
cloud_id  = "b1g3gq2pvbd3dnherq8j"
folder_id = "b1gio4d52dv3cbcba4ad"

начения cloud_id и folder_id хранятся отдельно в terraform.tfvars и не попадают в код ресурсов.




<img width="489" height="32" alt="Снимок экрана 2025-10-29 в 19 16 18" src="https://github.com/user-attachments/assets/62712e0f-a60f-4cd2-b14f-a4ff8ffec22d" />
<img width="656" height="183" alt="Снимок экрана 2025-10-29 в 19 40 49" src="https://github.com/user-attachments/assets/17b77754-3137-4eea-8ae9-737d59624d07" />


### Задание 2

1. Замените все хардкод-**значения** для ресурсов **yandex_compute_image** и **yandex_compute_instance** на **отдельные** переменные. К названиям переменных ВМ добавьте в начало префикс **vm_web_** .  Пример: **vm_web_name**.
2. Объявите нужные переменные в файле variables.tf, обязательно указывайте тип переменной. Заполните их **default** прежними значениями из main.tf. 
3. Проверьте terraform plan. Изменений быть не должно. 


### Решение 2

Все параметры для ресурсов yandex_compute_image и yandex_compute_instance вынесены в переменные.

Для веб-сервера используется префикс vm_web_
""

variable "vm_web_name" {
  type    = string
  default = "netology-develop-platform-web"
}
""
Конфигурация валидна:
<img width="471" height="49" alt="Снимок экрана 2025-10-29 в 19 29 31" src="https://github.com/user-attachments/assets/66400d0f-b81e-4690-be41-0ac70ce6a986" />

<img width="650" height="533" alt="Снимок экрана 2025-10-29 в 19 30 20" src="https://github.com/user-attachments/assets/676cd247-60a3-406a-add5-661ef94846b9" />

все значения вынесены в переменные, изменений нет.






### Задание 3

1. Создайте в корне проекта файл 'vms_platform.tf' . Перенесите в него все переменные первой ВМ.
2. Скопируйте блок ресурса и создайте с его помощью вторую ВМ в файле main.tf: **"netology-develop-platform-db"** ,  ```cores  = 2, memory = 2, core_fraction = 20```. Объявите её переменные с префиксом **vm_db_** в том же файле ('vms_platform.tf').  ВМ должна работать в зоне "ru-central1-b"
3. Примените изменения.

### Решение 3
В проект добавлен файл /home/zis/ter-homeworks/02/src/vms_platform.tf, в котором вынесен код создания виртуальных машин web и db.
Параметры вычислительных ресурсов (CPU, RAM, core_fraction) не заданы жёстко, а вынесены в переменные и локальные значения.
Общие метаданные и метки (labels) подключаются из locals.tf, что устраняет хардкод и делает код универсальным и масштабируемым.


Код файла vms_platform.tf

""
# vms_platform.tf
# Код без хардкода для создания ВМ web и db

data "yandex_compute_image" "ubuntu" {
  family = "ubuntu-2004-lts"
}

# Веб-серверы
resource "yandex_compute_instance" "web" {
  count       = 2
  name        = "web-${count.index + 1}"
  platform_id = "standard-v1"

  resources {
    cores         = var.vm_resources.web.cores
    memory        = var.vm_resources.web.memory
    core_fraction = var.vm_resources.web.core_fraction
  }

  boot_disk {
    initialize_params {
      image_id = data.yandex_compute_image.ubuntu.image_id
      type     = "network-hdd"
      size     = 10
    }
  }

  scheduling_policy {
    preemptible = true
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.develop.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.example.id]
  }

  metadata = local.metadata_common
  labels   = local.common_labels
}

# Виртуальные машины базы данных
resource "yandex_compute_instance" "db" {
  for_each    = var.db_instances
  name        = each.key
  platform_id = "standard-v1"

  resources {
    cores         = each.value.cores
    memory        = each.value.memory
    core_fraction = each.value.core_fraction
  }

  boot_disk {
    initialize_params {
      image_id = data.yandex_compute_image.ubuntu.image_id
      type     = "network-hdd"
      size     = 10
    }
  }

  scheduling_policy {
    preemptible = true
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.develop.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.example.id]
  }

  metadata = local.metadata_common
  labels   = local.common_labels
}
""

Файл variables.tf

""
variable "vm_resources" {
  description = "Параметры виртуальных машин"
  type = map(object({
    cores         = number
    memory        = number
    core_fraction = number
  }))
  default = {
    web = {
      cores         = 2
      memory        = 2
      core_fraction = 20
    }
  }
}

variable "db_instances" {
  description = "Параметры ВМ баз данных"
  type = map(object({
    cores         = number
    memory        = number
    core_fraction = number
  }))
  default = {
    db-main = {
      cores         = 4
      memory        = 4
      core_fraction = 50
    }
    db-replica = {
      cores         = 2
      memory        = 2
      core_fraction = 20
    }
  }
}
""

Файл locals.tf

""
locals {
  ssh_public_key = chomp(file("/home/zis/.ssh/id_ed25519.pub"))

  metadata_common = {
    serial-port-enable = 1
    ssh-keys           = "ubuntu:${local.ssh_public_key}"
  }

  common_labels = {
    project     = "netology"
    environment = "develop"
  }
}
""

од полностью без хардкода:

параметры вычислительных ресурсов вынесены в переменные (vm_resources, db_instances);

общие настройки (metadata_common, common_labels) вынесены в locals.tf;

добавлены теги (labels), чтобы можно было легко группировать ресурсы;

### Задание 4

1. Объявите в файле outputs.tf **один** output , содержащий: instance_name, external_ip, fqdn для каждой из ВМ в удобном лично для вас формате.(без хардкода!!!)
2. Примените изменения.

В качестве решения приложите вывод значений ip-адресов команды ```terraform output```.


### Решение 4

Файл outputs.tf

# Один output без хардкода: имя ВМ -> { external_ip, fqdn }
output "instances" {
  description = "Список ВМ: instance_name -> { external_ip, fqdn }"
  value = {
    for inst in concat(
      try(yandex_compute_instance.web, []),
      try(values(yandex_compute_instance.db), []),
      try([yandex_compute_instance.storage], [])
    ) :
    inst.name => {
      external_ip = try(inst.network_interface[0].nat_ip_address, null)
      fqdn        = inst.fqdn
    }
  }
}

### Задание 5

1. В файле locals.tf опишите в **одном** local-блоке имя каждой ВМ, используйте интерполяцию ${..} с НЕСКОЛЬКИМИ переменными по примеру из лекции.
2. Замените переменные внутри ресурса ВМ на созданные вами local-переменные.
3. Примените изменения.

### Решение 5
Как у меня сделано :
Файл disk_vm.tf

""
resource "yandex_compute_disk" "storage_disks" {
  count = 3
  name  = "storage-disk-${count.index + 1}"
  size  = 1
  type  = "network-hdd"
  zone  = var.default_zone
}

resource "yandex_compute_instance" "storage" {
  name        = "storage"
  platform_id = "standard-v1"

  resources {
    cores         = 2
    memory        = 2
    core_fraction = 20
  }

  boot_disk {
    initialize_params {
      image_id = data.yandex_compute_image.ubuntu.image_id
      type     = "network-hdd"
      size     = 10
    }
  }

  # вот самое важное - dynamic
  dynamic "secondary_disk" {
    for_each = yandex_compute_disk.storage_disks
    content {
      disk_id = secondary_disk.value.id
    }
  }

  scheduling_policy {
    preemptible = true
  }

  network_interface {
    subnet_id          = yandex_vpc_subnet.develop.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.example.id]
  }

  metadata = local.metadata_common
}
""
Дополнительные диски не захардкожены и не перечисляются вручную.
Диски сначала создаются ресурсом yandex_compute_disk.storage_disks с count = 3, а потом подключаются к ВМ storage через dynamic "secondary_disk" и цикл for_each.
Если мне нужно 5 дисков вместо 3 — я меняю только count = 5 в одном месте, сам код ресурса storage не меняется.
Это устраняет хардкод конфигурации дисков.


### Задание 6

Для выполнения задания 6 я переработал конфигурацию Terraform так, чтобы устранить хардкод и реализовать работу с локальными переменными, картами (map) и выходными переменными (output).

файл locals.tf

В этом файле я вынес общие параметры для всех виртуальных машин, SSH-ключ и общие метки.
Путь к публичному ключу хранится в переменной, чтобы избежать жёстких путей в коде.

"locals {
  # общие параметры виртуальных машин
  vm_resources = {
    cores         = 2
    memory        = 2
    core_fraction = 20
  }

  # общий metadata-блок, используется для всех ВМ
  ssh_public_key = chomp(file(var.ssh_public_key_path))
  metadata_common = {
    serial-port-enable = 1
    ssh-keys           = "ubuntu:${local.ssh_public_key}"
  }

  # общие теги для всех ресурсов
  common_labels = {
    project     = "netology"
    environment = "develop"
  }
}


""
Локальные переменные позволяют не дублировать одни и те же значения (CPU, RAM, SSH-ключ, теги) в каждом ресурсе.
Теперь любое изменение параметров можно сделать в одном месте, не редактируя десятки файлов.
Файл variables.tf — добавлена переменная для пути к ключу и карта параметров ВМ

"
# путь к публичному SSH-ключу
variable "ssh_public_key_path" {
  description = "Путь к публичному SSH-ключу пользователя"
  type        = string
  default     = "/home/zis/.ssh/id_ed25519.pub"
}

# карта с параметрами ресурсов виртуальных машин
variable "vm_resources_map" {
  description = "Параметры виртуальных машин по ролям"
  type = map(object({
    cores         = number
    memory        = number
    core_fraction = number
  }))

  default = {
    web = {
      cores         = 2
      memory        = 2
      core_fraction = 20
    }
    db = {
      cores         = 4
      memory        = 4
      core_fraction = 50
    }
  }
}
"
Переменная vm_resources_map задаёт разные параметры для ролей web и db.
Теперь можно гибко управлять характеристиками машин, не меняя структуру кода.

Использование locals и map в коде виртуальных машин
count-vm.tf (web-серверы)
"
resource "yandex_compute_instance" "web" {
  count       = 2
  name        = "web-${count.index + 1}"
  platform_id = "standard-v1"

  resources {
    cores         = var.vm_resources_map["web"].cores
    memory        = var.vm_resources_map["web"].memory
    core_fraction = var.vm_resources_map["web"].core_fraction
  }

  boot_disk {
    initialize_params {
      image_id = data.yandex_compute_image.ubuntu.image_id
      type     = "network-hdd"
      size     = 10
    }
  }

  scheduling_policy { preemptible = true }

  network_interface {
    subnet_id          = yandex_vpc_subnet.develop.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.example.id]
  }

  labels   = local.common_labels
  metadata = local.metadata_common
}
"

for_each-vm.tf (базы данных)
"
resource "yandex_compute_instance" "db" {
  for_each    = { for v in var.each_vm : v.vm_name => v }
  name        = "db-${each.key}"
  platform_id = "standard-v1"

  resources {
    cores         = var.vm_resources_map["db"].cores
    memory        = var.vm_resources_map["db"].memory
    core_fraction = var.vm_resources_map["db"].core_fraction
  }

  boot_disk {
    initialize_params {
      image_id = data.yandex_compute_image.ubuntu.image_id
      type     = "network-hdd"
      size     = each.value.disk_volume
    }
  }

  scheduling_policy { preemptible = true }

  network_interface {
    subnet_id          = yandex_vpc_subnet.develop.id
    nat                = true
    security_group_ids = [yandex_vpc_security_group.example.id]
  }

  labels   = local.common_labels
  metadata = local.metadata_common
}
"
Вместо прямых чисел (хардкода) значения ресурсов берутся из var.vm_resources_map,
а общие метки и SSH-ключи — из locals. Это делает код универсальным и переносимым.


Файл outputs.tf
Добавлены выходные переменные для вывода идентификаторов и IP-адресов созданных ресурсов.

output "network_id" {
  description = "ID созданной сети"
  value       = yandex_vpc_network.develop.id
}

output "subnet_id" {
  description = "ID созданной подсети"
  value       = yandex_vpc_subnet.develop.id
}

output "web_external_ips" {
  description = "Публичные IP web-серверов"
  value       = [for w in yandex_compute_instance.web : w.network_interface[0].nat_ip_address]
}

output "db_external_ips" {
  description = "Публичные IP баз данных"
  value       = [for d in yandex_compute_instance.db : d.network_interface[0].nat_ip_address]
}

output "storage_external_ip" {
  description = "Публичный IP хранилища"
  value       = yandex_compute_instance.storage.network_interface[0].nat_ip_address
}


После применения Terraform выводит все ключевые параметры инфраструктуры —
ID сети, подсети и IP-адреса ВМ. Это избавляет от ручного копирования данных в другие системы
